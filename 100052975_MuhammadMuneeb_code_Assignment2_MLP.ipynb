{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Assignment_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxF0lT-iX_3j"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers.core import Dense, Dropout, Activation,ActivityRegularization\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJu33zI14JIN"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2m9vNDzX_3n"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHOnFX2cX_3q"
      },
      "source": [
        "# building the input vector from the 28x28 pixels\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1] * X_train.shape[2])\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL3cAl7GX_3s"
      },
      "source": [
        "# normalizing the data to help with the training\n",
        "X_train= X_train/255\n",
        "X_test=X_test/255"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v147fvzjX_3u"
      },
      "source": [
        "Y_train = to_categorical(y_train)\n",
        "Y_test = to_categorical(y_test)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiUn58mK4_Jm"
      },
      "source": [
        "#plotting function\n",
        "def plotting(history):\n",
        "  fig = plt.figure()\n",
        "  history_dict = history.history\n",
        "  print(history_dict.keys())\n",
        "  plt.subplot(2,1,1)\n",
        "  plt.plot(history_dict['accuracy'])\n",
        "  plt.plot(history_dict['val_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['Training Set', 'Validation Set'], loc='lower right')\n",
        "\n",
        "  plt.subplot(2,1,2)\n",
        "\n",
        "\n",
        "  plt.plot( history_dict['loss'])\n",
        "  plt.plot( history_dict['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['Training Set', 'Validation Set'], loc='upper right')\n",
        "\n",
        "  plt.tight_layout()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnRKTfoCX_3w"
      },
      "source": [
        "import time\n",
        "\n",
        "# building a linear stack of layers with the sequential model\n",
        "#Type of changes\n",
        " \n",
        "\n",
        " \n",
        "start_time = time.time()\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_shape=(784,)))\n",
        "model.add(Activation('relu'))                            \n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# compiling the sequential model\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "# training the model and saving metrics in history\n",
        "history = model.fit(X_train, Y_train,\n",
        "          batch_size=128, epochs=5,\n",
        "          validation_split=0.3)\n",
        "\n",
        "plotting(history)\n",
        "loss, acc = model.evaluate(X_test, Y_test)\n",
        "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw53k_d5qTxG"
      },
      "source": [
        "This is the basic Neural Network that we build."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbsPs77OX_33"
      },
      "source": [
        "#activation functions \n",
        "activationFunctions = [\"sigmoid\",\"relu\",\"softmax\",\"tanh\"]\n",
        "import time\n",
        "t = []\n",
        "l= []\n",
        "a = []\n",
        "for activation in activationFunctions:\n",
        "  print(activation)\n",
        "  start_time = time.time()\n",
        "  model = Sequential()\n",
        "  model.add(Dense(512, input_shape=(784,)))\n",
        "  model.add(Activation(activation))                            \n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation(activation))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  model.add(Dense(10))\n",
        "  model.add(Activation(\"softmax\"))\n",
        "\n",
        "  # compiling the sequential model\n",
        "  model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "  # training the model and saving metrics in history\n",
        "  history = model.fit(X_train, Y_train,\n",
        "          batch_size=128, epochs=5,\n",
        "          validation_split=0.3)\n",
        "\n",
        "  #plotting(history)\n",
        "  loss, acc = model.evaluate(X_test, Y_test)\n",
        "  l.append(loss)\n",
        "  a.append((100.0 * acc))\n",
        "  t.append(time.time() - start_time)\n",
        "\n",
        "print(\"loss\")\n",
        "print(l)\n",
        "print(\"accuracy\")\n",
        "print(a)\n",
        "print(\"Time for execution\")\n",
        "print(t)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHek8cz7qluO"
      },
      "source": [
        "Here I am using different acctivation functions.\n",
        "\n",
        "ActivationFunctions = [\"sigmoid\",\"relu\",\"softmax\",\"tanh\"]\n",
        "\n",
        "Relu is the best activation function for this dataset.\n",
        "\n",
        "If we use softmax then accuracy is not that much high and network performance is bad.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-Zc_n9TBP-z"
      },
      "source": [
        "#dropout \n",
        "ddropout = [0.2,0.3,0.5]\n",
        "import time\n",
        "t = []\n",
        "l= []\n",
        "a = []\n",
        "for d in ddropout:\n",
        " \n",
        "  start_time = time.time()\n",
        "  model = Sequential()\n",
        "  model.add(Dense(512, input_shape=(784,)))\n",
        "  model.add(Activation(\"relu\"))                            \n",
        "  model.add(Dropout(d))\n",
        "\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(Dropout(d))\n",
        "\n",
        "  model.add(Dense(10))\n",
        "  model.add(Activation(\"softmax\"))\n",
        "\n",
        "  # compiling the sequential model\n",
        "  model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "  # training the model and saving metrics in history\n",
        "  history = model.fit(X_train, Y_train,\n",
        "          batch_size=128, epochs=5,\n",
        "          validation_split=0.3)\n",
        "\n",
        "  #plotting(history)\n",
        "  loss, acc = model.evaluate(X_test, Y_test)\n",
        "  l.append(loss)\n",
        "  a.append((100.0 * acc))\n",
        "  t.append(time.time() - start_time)\n",
        "\n",
        "print(\"loss\")\n",
        "print(l)\n",
        "print(\"accuracy\")\n",
        "print(a)\n",
        "print(\"Time for execution\")\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRv1B9JxrRz4"
      },
      "source": [
        "Changing dropout has no effect on accuracy but the time of execution is more for dropout = 0.3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Odu2QH0VB-pK"
      },
      "source": [
        "#optimizer \n",
        "optimizer = [\"Adam\",\"SGD\",\"RMSprop\",\"Ftrl\"]\n",
        "import time\n",
        "t = []\n",
        "l= []\n",
        "a = []\n",
        "for o in optimizer:\n",
        " \n",
        "  start_time = time.time()\n",
        "  model = Sequential()\n",
        "  model.add(Dense(512, input_shape=(784,)))\n",
        "  model.add(Activation(\"relu\"))                            \n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  model.add(Dense(10))\n",
        "  model.add(Activation(\"softmax\"))\n",
        "\n",
        "  # compiling the sequential model\n",
        "  model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=o)\n",
        "  # training the model and saving metrics in history\n",
        "  history = model.fit(X_train, Y_train,\n",
        "          batch_size=128, epochs=5,\n",
        "          validation_split=0.3)\n",
        "\n",
        "  #plotting(history)\n",
        "  loss, acc = model.evaluate(X_test, Y_test)\n",
        "  l.append(loss)\n",
        "  a.append((100.0 * acc))\n",
        "  t.append(time.time() - start_time)\n",
        "print(\"loss\")\n",
        "print(l)\n",
        "print(\"accuracy\")\n",
        "print(a)\n",
        "print(\"Time for execution\")\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNF99OzoreAX"
      },
      "source": [
        "Optimizer has major effect on network performance if we use Ftrl optimizer we get very low accuracy of about only 11 percent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwqZV2PfC1Mc"
      },
      "source": [
        "#batchsize\n",
        "batchsize = [128,250,500]\n",
        "import time\n",
        "t = []\n",
        "l= []\n",
        "a = []\n",
        "for b in batchsize:\n",
        " \n",
        "  start_time = time.time()\n",
        "  model = Sequential()\n",
        "  model.add(Dense(512, input_shape=(784,)))\n",
        "  model.add(Activation(\"relu\"))                            \n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  model.add(Dense(10))\n",
        "  model.add(Activation(\"softmax\"))\n",
        "\n",
        "  # compiling the sequential model\n",
        "  model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='Adam')\n",
        "  # training the model and saving metrics in history\n",
        "  history = model.fit(X_train, Y_train,\n",
        "          batch_size=b, epochs=5,\n",
        "          validation_split=0.3)\n",
        "\n",
        "  #plotting(history)\n",
        "  loss, acc = model.evaluate(X_test, Y_test)\n",
        "  l.append(loss)\n",
        "  a.append((100.0 * acc))\n",
        "  t.append(time.time() - start_time)\n",
        "\n",
        "print(\"loss\")\n",
        "print(l)\n",
        "print(\"accuracy\")\n",
        "print(a)\n",
        "print(\"Time for execution\")\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCKk8QsKr-2x"
      },
      "source": [
        "Changing batch size has major effect on execution time of our network. For batch size 500 time is just 16 second as compared to 25 second required for normal execution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZceoLtQD1Pz"
      },
      "source": [
        "#epochs number\n",
        "epochsnumber = [5,10,20]\n",
        "import time\n",
        "t = []\n",
        "l= []\n",
        "a = []\n",
        "for e in epochsnumber:\n",
        " \n",
        "  start_time = time.time()\n",
        "  model = Sequential()\n",
        "  model.add(Dense(512, input_shape=(784,)))\n",
        "  model.add(Activation(\"relu\"))                            \n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  model.add(Dense(10))\n",
        "  model.add(Activation(\"softmax\"))\n",
        "\n",
        "  # compiling the sequential model\n",
        "  model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='Adam')\n",
        "  # training the model and saving metrics in history\n",
        "  history = model.fit(X_train, Y_train,\n",
        "          batch_size=128, epochs=e,\n",
        "          validation_split=0.3)\n",
        "\n",
        "  #plotting(history)\n",
        "  loss, acc = model.evaluate(X_test, Y_test)\n",
        "  l.append(loss)\n",
        "  a.append((100.0 * acc))\n",
        "  t.append(time.time() - start_time)\n",
        "\n",
        "print(\"loss\")\n",
        "print(l)\n",
        "print(\"accuracy\")\n",
        "print(a)\n",
        "print(\"Time for execution\")\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw_eylJUsO9y"
      },
      "source": [
        "Changing number of epochs in this does not produce any effect because model is already stable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9zFSPpCECHv"
      },
      "source": [
        "#weights initiation methods\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import initializers\n",
        "import tensorflow as tf\n",
        " \n",
        "initiationmethods = [tf.keras.initializers.Ones(),tf.keras.initializers.Zeros(),tf.keras.initializers.RandomNormal(mean=0., stddev=1.)]\n",
        "import time\n",
        "t = []\n",
        "l= []\n",
        "a = []\n",
        "for ii in initiationmethods:\n",
        "  start_time = time.time()\n",
        "  model = Sequential()\n",
        "  model.add(Dense(512, input_shape=(784,),kernel_initializer=ii))\n",
        "  model.add(Activation(\"relu\"))                            \n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  model.add(Dense(512,kernel_initializer=ii))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  model.add(Dense(10,kernel_initializer=ii))\n",
        "  model.add(Activation(\"softmax\"))\n",
        "\n",
        "  # compiling the sequential model\n",
        "  model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='Adam')\n",
        "  # training the model and saving metrics in history\n",
        "  history = model.fit(X_train, Y_train,\n",
        "          batch_size=128, epochs=5,\n",
        "          validation_split=0.3)\n",
        "\n",
        "  #plotting(history)\n",
        "  loss, acc = model.evaluate(X_test, Y_test)\n",
        "  l.append(loss)\n",
        "  a.append((100.0 * acc))\n",
        "  t.append(time.time() - start_time)\n",
        "\n",
        "print(\"loss\")\n",
        "print(l)\n",
        "print(\"accuracy\")\n",
        "print(a)\n",
        "print(\"Time for execution\")\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r6Tfarlsawj"
      },
      "source": [
        "This point is very important. If we are using same weights for network then it will not converge properly. For 0's and 1's it gives accuracy of about 11 and 10 percent respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvkc5OSiNy2S"
      },
      "source": [
        "#regularization types\n",
        "#l1 and l2 regularization\n",
        "#l1\n",
        "l1 = [0.02,0.05,0.1]\n",
        "import time\n",
        "t = []\n",
        "l= []\n",
        "a = []\n",
        "for ll in l1:\n",
        " \n",
        "  start_time = time.time()\n",
        "  model = Sequential()\n",
        "  model.add(Dense(512, input_shape=(784,)))\n",
        "  model.add(Activation(\"relu\"))                            \n",
        "  model.add(ActivityRegularization(ll,0))\n",
        "\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(ActivityRegularization(ll,0))\n",
        "\n",
        "  model.add(Dense(10))\n",
        "  model.add(Activation(\"softmax\"))\n",
        "\n",
        "  # compiling the sequential model\n",
        "  model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='Adam')\n",
        "  # training the model and saving metrics in history\n",
        "  history = model.fit(X_train, Y_train,\n",
        "          batch_size=128, epochs=5,\n",
        "          validation_split=0.3)\n",
        "\n",
        "  #plotting(history)\n",
        "  loss, acc = model.evaluate(X_test, Y_test)\n",
        "  l.append(loss)\n",
        "  a.append((100.0 * acc))\n",
        "  t.append(time.time() - start_time)\n",
        "\n",
        "print(\"loss\")\n",
        "print(l)\n",
        "print(\"accuracy\")\n",
        "print(a)\n",
        "print(\"Time for execution\")\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4uceMzYsttf"
      },
      "source": [
        "For high l1 value like 0.05 or 1 model is giving very low accuracy which means it is unable to learn proper weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQbfbsrv7uLS"
      },
      "source": [
        "import time\n",
        "\n",
        "#regularization types\n",
        "#l1 and l2 regularization\n",
        "#l2\n",
        "l2 = [0.2,0.3,0.5]\n",
        "import time\n",
        "t = []\n",
        "l= []\n",
        "a = []\n",
        "for ll in l2:\n",
        "  start_time = time.time()\n",
        "  model = Sequential()\n",
        "  model.add(Dense(512, input_shape=(784,)))\n",
        "  model.add(Activation(\"relu\"))                            \n",
        "  model.add(ActivityRegularization(0,ll))\n",
        "\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(ActivityRegularization(0,ll))\n",
        "\n",
        "  model.add(Dense(10))\n",
        "  model.add(Activation(\"softmax\"))\n",
        "\n",
        "  # compiling the sequential model\n",
        "  model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='Adam')\n",
        "  # training the model and saving metrics in history\n",
        "  history = model.fit(X_train, Y_train,\n",
        "          batch_size=128, epochs=5,\n",
        "          validation_split=0.3)\n",
        "\n",
        "  #plotting(history)\n",
        "  loss, acc = model.evaluate(X_test, Y_test)\n",
        "  l.append(loss)\n",
        "  a.append((100.0 * acc))\n",
        "  t.append(time.time() - start_time)\n",
        "\n",
        "print(\"loss\")\n",
        "print(l)\n",
        "print(\"accuracy\")\n",
        "print(a)\n",
        "print(\"Time for execution\")\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGorRyvptD-2"
      },
      "source": [
        "For high l2 value like 0.03 or 0.05 model accuracy is decreasing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeZmLxXwEDrg"
      },
      "source": [
        "import time\n",
        "#add or remove hidden layers\n",
        "#part1\n",
        "start_time = time.time()\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_shape=(784,)))\n",
        "model.add(Activation('relu'))                            \n",
        "model.add(Dropout(0.2))\n",
        " \n",
        "\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# compiling the sequential model\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "# training the model and saving metrics in history\n",
        "history = model.fit(X_train, Y_train,\n",
        "          batch_size=128, epochs=5,\n",
        "          validation_split=0.3)\n",
        "\n",
        "plotting(history)\n",
        "loss, acc = model.evaluate(X_test, Y_test)\n",
        "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZimyVVz1tpqp"
      },
      "source": [
        "Using only one hidden layer reduces accuray by 0.1 percent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XfNVWDiEdAc"
      },
      "source": [
        "import time\n",
        "#add or remove hidden layers\n",
        "#part2\n",
        "start_time = time.time()\n",
        "model = Sequential()\n",
        "model.add(Dense(100, input_shape=(784,)))\n",
        "model.add(Activation('relu'))                            \n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(20))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# compiling the sequential model\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "# training the model and saving metrics in history\n",
        "history = model.fit(X_train, Y_train,\n",
        "          batch_size=128, epochs=5,\n",
        "          validation_split=0.3)\n",
        "\n",
        "plotting(history)\n",
        "loss, acc = model.evaluate(X_test, Y_test)\n",
        "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LmJQYF_th4e"
      },
      "source": [
        "If we use very less parameters in the hidden network training will be very fast but network would not be able to learn more parameters for accurate predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHKeIhCYE2Iy"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    }
  ]
}